<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>CS184 HW1 - Rasterizer</title>
</head>
<body>
  <h1>Homework 1: Rasterizer</h1>
  <p>Yash Shah — CS184 Spring 2026</p>

  <p><b>Live Website:</b> 
  <a href="https://yds2330.github.io/cs184-sp26/hw1.html">
  https://yds2330.github.io/cs184-sp26/hw1.html
  </a>
  </p>

  <h2>Task 1: Drawing Single-Color Triangles</h2>

  <h3>Implementation</h3>
  <p>
    To rasterize a triangle, I first compute its axis-aligned bounding box by taking the minimum and maximum
    x and y values across the triangle’s three vertices. I then iterate over all pixels within this box and
    sample at the center of each pixel using (x + 0.5, y + 0.5), as specified in the assignment.
  </p>
  <p>
    For each sample point, I use edge functions to test whether the point lies inside the triangle. If the
    sample is inside the triangle or on its boundary, I fill the pixel with the triangle’s color using
    <code>fill_pixel()</code>.
  </p>

  <h3>Efficiency</h3>
  <p>
    My algorithm only checks pixels inside the triangle’s bounding box rather than scanning the entire framebuffer.
    Each pixel in the bounding box is tested once, so the runtime is proportional to the area of the bounding box.
    This is no worse than a method that checks every sample in the triangle’s bounding box.
  </p>

  <h3>Result (basic/test4.svg + Pixel Inspector)</h3>
  <p>
    The screenshot below was generated using the GUI <code>S</code> hotkey, with the pixel inspector enabled and centered
    on an interesting edge region.
  </p>

  <img src="task1_test4_pixel_inspector.png.png" width="900" />
  
  <h3>Additional Screenshot</h3>
  <img src="task1_test4.png" width="900" />


  <hr>

  <h2>Task 2: Antialiasing by Supersampling</h2>

  <h3>Implementation</h3>

  <p>
  To implement supersampling, I modified the rasterizer to maintain a
  separate supersample buffer (<code>sample_buffer</code>) that stores
  <code>sample_rate</code> color samples per pixel instead of a single
  sample. The buffer size is therefore
  <code>width × height × sample_rate</code>.
  </p>

  <p>
  For triangle rasterization, instead of sampling once at the center
  of each pixel, I subdivide each pixel into a
  <code>sqrt(sample_rate) × sqrt(sample_rate)</code> grid of evenly spaced
  subpixel locations. For each subpixel sample, I perform the same
  edge-function point-in-triangle test used in Task 1.
  If the sample lies inside or on the boundary of the triangle,
  I write the triangle’s color into the corresponding location in
  the supersample buffer.
  </p>

  <p>
  After all primitives are rasterized, I resolve the supersamples
  into the final framebuffer inside
  <code>resolve_to_framebuffer()</code>.
  For each pixel, I average the colors of its
  <code>sample_rate</code> subpixel samples and write the averaged
  result into the RGB framebuffer. This averaging step produces
  partial coverage values near edges, which reduces aliasing artifacts.
  </p>

  <h3>Performance Considerations</h3>

  <p>
  The runtime of the rasterizer increases approximately linearly
  with the sample rate, since each pixel now requires
  <code>sample_rate</code> coverage tests instead of one.
  However, rasterization is still restricted to the triangle’s
  axis-aligned bounding box, so performance remains proportional
  to the bounding box area rather than the entire framebuffer.
  </p>

  <h3>Results (basic/test4.svg)</h3>

  <p><strong>Supersample Rate = 1</strong></p>
  <img src="screenshot_2-24_20-25-13.png" width="900" />

  <p><strong>Supersample Rate = 4</strong></p>
  <img src="screenshot_2-24_20-25-30.png" width="900" />

  <p><strong>Supersample Rate = 16</strong></p>
  <img src="screenshot_2-24_20-26-2.png" width="900" />

  <h3>Analysis</h3>

  <p>
  At a sample rate of 1, triangle edges exhibit visible aliasing
  (stair-step artifacts), especially along shallow or diagonal edges.
  This occurs because each pixel is classified as either fully inside
  or fully outside the triangle.
  </p>

  <p>
  At a sample rate of 4, edge transitions become smoother because
  pixels along boundaries may now have partial coverage. The
  averaged subpixel samples produce intermediate colors that reduce
  the stair-step effect.
  </p>

  <p>
  At a sample rate of 16, edges appear significantly smoother,
  with much finer transitions along triangle boundaries.
  The improvement is especially noticeable along thin or slanted edges,
  where higher sampling density better approximates the true geometric
  coverage of the triangle.
  </p>

  <hr>

  <h3>Extra Credit: Jittered Sampling</h3>

  <p>
  In addition to regular grid supersampling, I implemented jittered
  sampling. Instead of placing subpixel samples at fixed grid locations,
  each sample position is randomly perturbed within its subpixel cell
  using a deterministic hash-based offset. This keeps sampling stable
  between frames while introducing randomness in sample placement.
  </p>

  <p>
  Grid supersampling reduces aliasing but may introduce structured
  patterns along certain edges due to the regular alignment of the grid.
  Jittered sampling breaks this regularity and distributes error more
  randomly, which reduces visible structured artifacts.
  </p>

  <p><strong>Grid Sampling (sample rate = 16)</strong></p>
  <img src="screenshot_2-24_20-31-4.png" width="900" />

  <p><strong>Jittered Sampling (sample rate = 16)</strong></p>
  <img src="screenshot_2-24_20-33-56.png" width="900" />

  <p>
  Compared to regular grid sampling, jittered sampling produces
  less structured stair-step artifacts along diagonal edges.
  While both methods significantly reduce aliasing compared to
  sample rate 1, jittered sampling appears visually smoother
  because the aliasing error is less correlated.
  </p>


  <hr>

  <h2>Task 3: Transforms</h2>

  <h3>Custom Robot (my_robot.svg)</h3>

  <p>
  After implementing the <code>translate</code>, <code>scale</code>, and
  <code>rotate</code> transformation matrices in <code>transforms.cpp</code>,
  the original <code>robot.svg</code> rendered correctly.
  To demonstrate hierarchical transformations, I created a modified
  version of the robot called <code>my_robot.svg</code>.
  </p>

  <p>
  I changed the robot’s color and adjusted several group transforms
  to create a more dynamic pose. The right arm group was rotated
  (using <code>rotate(-40)</code>) to simulate a waving motion.
  The left and right leg groups were rotated in opposite directions
  (<code>rotate(20)</code> and <code>rotate(-20)</code>) to give the appearance
  of running. I also slightly rotated the head to make the pose
  feel more expressive.
  </p>

  <p>
  Because each limb is defined inside a <code>&lt;g&gt;</code> group,
  applying a transformation to the group automatically affects
  all child polygons within that limb. This demonstrates how
  hierarchical transforms propagate through the SVG transformation
  stack via matrix multiplication.
  </p>

  <img src="screenshot_2-24_23-12-33.png" width="900" />

  <hr>
  <h2>Task 4: Barycentric Coordinates</h2>

  <h3>Explanation</h3>
  <p>
  Barycentric coordinates represent any point inside a triangle as a weighted combination
  of the triangle’s three vertices. For a point P inside a triangle with vertices V0, V1,
  and V2, we compute three weights (α, β, γ) such that:
  </p>

  <p>
  P = αV0 + βV1 + γV2, and α + β + γ = 1.
  </p>

  <p>
  Intuitively, each weight measures how close the point is to a vertex. If P is near V0,
  then α is large; if P lies on the edge opposite V0, then α becomes 0. In our rasterizer,
  we compute these weights using edge functions (signed area tests). A point is inside the
  triangle if the weights are all nonnegative (or all nonpositive, depending on winding).
  </p>

  <p>
  Once we have (α, β, γ), we can smoothly interpolate any per-vertex quantity across the
  triangle. For this task, we interpolate color: the final color at P is α·C0 + β·C1 + γ·C2.
  This produces smooth color gradients instead of flat-colored triangles.
  </p>

  <h3>Gradient Example (interpolated colors)</h3>
  <img src="screenshot_2-25_15-54-22.png" width="900" />

  <h3>Color Wheel Result (test7.svg, sample rate 1)</h3>
  <img src="screenshot_2-24_23-58-21.png" width="900" />

  <h2>Task 5: Pixel Sampling for Texture Mapping</h2>

  <h3>Overview</h3>

  <p>
  Pixel sampling determines how we compute the color of a pixel when mapping a texture onto a triangle. 
  After computing barycentric coordinates for each sub-sample inside a pixel, we interpolate the 
  corresponding texture coordinates (u, v). These (u, v) coordinates lie in the continuous range [0, 1], 
  but the texture itself is stored as a discrete grid of texels. Pixel sampling determines how we convert 
  this continuous texture coordinate into a final color value.
  </p>

  <p>
  In this task, I implemented two pixel sampling methods:
  </p>

  <ul>
    <li><strong>Nearest neighbor sampling</strong></li>
    <li><strong>Bilinear interpolation</strong></li>
  </ul>

  <p>
  For Task 5, only level 0 of the mipmap (full resolution texture) was used.
  </p>

  <hr>

  <h3>Implementation Details</h3>

  <p>
  In <code>rasterize_textured_triangle</code>, I reused the supersampling and barycentric interpolation 
  logic from Task 4. For each sub-sample inside a pixel:
  </p>

  <ol>
    <li>Compute barycentric coordinates.</li>
    <li>Interpolate texture coordinates (u, v).</li>
    <li>Use the selected pixel sampling method (psm) to sample the texture at level 0.</li>
    <li>Store the resulting color in the sample buffer.</li>
  </ol>

  <p>
  Nearest sampling converts (u, v) into the closest texel index using rounding. 
  Bilinear sampling computes a weighted average of the four surrounding texels using linear interpolation 
  in both the x and y directions.
  </p>

  <hr>

  <h3>Nearest vs. Bilinear Sampling</h3>

  <h4>Nearest Sampling</h4>

  <p>
  Nearest neighbor sampling selects the single texel whose center is closest to the 
  continuous (u, v) coordinate. This method is fast and simple but can produce visible 
  blockiness and abrupt color transitions.
  </p>

  <img src="nearest_pixel_sampler.png" width="600">
  <p><em>Nearest sampling, 1 sample per pixel</em></p>

  <img src="16_pixel_nearest.png" width="600">
  <p><em>Nearest sampling, 16 samples per pixel</em></p>

  <p>
  With 1 sample per pixel, the texture appears slightly blocky, especially when zoomed in 
  around coastlines and grid lines. Increasing to 16 samples per pixel smooths triangle 
  edges (geometry aliasing), but the texture itself still exhibits blockiness because 
  nearest sampling does not blend between texels.
  </p>

  <hr>

  <h4>Bilinear Sampling</h4>

  <p>
  Bilinear interpolation samples the four surrounding texels and blends them 
  based on the fractional part of the texture coordinate. This produces smoother 
  transitions between texels.
  </p>

  <img src="Bbilinear_1.png" width="600">
  <p><em>Bilinear sampling, 1 sample per pixel</em></p>

  <img src="bilinear_16.png" width="600">
  <p><em>Bilinear sampling, 16 samples per pixel</em></p>

  <p>
  Compared to nearest sampling, bilinear interpolation produces smoother 
  coastlines and grid lines. The texture transitions appear softer, and 
  individual texel boundaries are less visible. With 16 samples per pixel, 
  both texture smoothness and geometric edge smoothness improve further.
  </p>

  <hr>

  <h3>Pixel Inspector Comparison</h3>

  <p>
  Using the pixel inspector and zooming into the grid lines on the globe, 
  the difference between the two methods becomes more apparent.
  </p>

  <img src="pixel_inspector_normal.png" width="400">
  <p><em>Nearest sampling (zoomed view)</em></p>

  <img src="pixel_inspector_bilinear.png" width="400">
  <p><em>Bilinear sampling (zoomed view)</em></p>

  <p>
  Nearest sampling produces visible square texel blocks and abrupt color changes. 
  Bilinear sampling blends neighboring texels, producing smoother gradients 
  and less noticeable pixel boundaries.
  </p>

  <hr>

  <h3>Discussion: When Is the Difference Large?</h3>

  <p>
  The difference between nearest and bilinear sampling becomes more significant when:
  </p>

  <ul>
    <li>The texture contains high-frequency details (thin lines, sharp edges, text).</li>
    <li>The texture is magnified (zoomed in).</li>
    <li>The surface is viewed at an angle.</li>
  </ul>

  <p>
  Nearest sampling preserves sharp texel boundaries, which can result in 
  visible aliasing artifacts. Bilinear sampling reduces these artifacts by 
  interpolating between texels, creating smoother transitions. However, bilinear 
  sampling can slightly blur fine details compared to nearest sampling.
  </p>

  <p>
  In summary, nearest sampling is faster but produces more aliasing, 
  while bilinear sampling improves visual quality by smoothing texture transitions.
  </p>

  <hr>

  <h3>Relationship Between Pixel Sampling and Supersampling</h3>

  <p>
  It is important to distinguish between pixel sampling and supersampling. 
  Pixel sampling determines how a texture color is computed from texture coordinates (u, v). 
  Nearest and bilinear sampling affect how smoothly the texture itself appears.
  </p>

  <p>
  Supersampling, on the other hand, reduces aliasing along triangle edges by 
  taking multiple sub-samples within each pixel and averaging them. Increasing 
  the supersample rate improves geometric edge smoothness but does not change 
  how individual texels are filtered.
  </p>

  <p>
  Therefore:
  </p>

  <ul>
    <li>Nearest vs. bilinear sampling affects texture sharpness and smoothness.</li>
    <li>1 sample vs. 16 samples per pixel affects triangle edge aliasing.</li>
  </ul>

  <p>
  These two techniques address different sources of aliasing in the rendering pipeline.
  </p>

  <h2>Task 6: Level Sampling with Mipmaps for Texture Mapping</h2>

  <h3>Overview</h3>
  <p>
  In this task, I implemented level sampling using mipmaps to reduce texture aliasing.
  When a textured surface becomes small on the screen, many texels from the original
  high-resolution texture map to a single screen pixel. If we always sample from level 0,
  high-frequency texture detail causes shimmering and moiré artifacts.
  </p>

  <p>
  Mipmaps address this by storing prefiltered versions of the texture at progressively
  lower resolutions. Level sampling determines which mipmap level best matches the
  pixel footprint on the screen.
  </p>

  <hr>

  <h3>Implementation Details</h3>

  <p>
  Inside <code>RasterizerImp::rasterize_textured_triangle</code>, for each sub-sample
  I computed the UV coordinates at three screen positions:
  </p>

  <ul>
    <li>(x, y)</li>
    <li>(x + 1, y)</li>
    <li>(x, y + 1)</li>
  </ul>

  <p>
  These were stored in <code>sp.p_uv</code>, <code>sp.p_dx_uv</code>, and
  <code>sp.p_dy_uv</code> respectively and passed into <code>Texture::get_level</code>.
  </p>

  <p>
  In <code>get_level</code>, I:
  </p>

  <ul>
    <li>Computed the UV derivatives: (p_dx_uv − p_uv) and (p_dy_uv − p_uv).</li>
    <li>Scaled them into texel space using the width and height of mip level 0.</li>
    <li>Computed their magnitudes.</li>
    <li>Took the maximum magnitude as the texture footprint.</li>
    <li>Returned D = log2(footprint) as the mip level.</li>
  </ul>

  <p>
  Finally, in <code>Texture::sample</code>, I implemented:
  </p>

  <ul>
    <li><strong>L_ZERO</strong>: always sample from mip level 0.</li>
    <li><strong>L_NEAREST</strong>: round D to the nearest integer mip level.</li>
    <li><strong>L_LINEAR</strong>: linearly interpolate between floor(D) and ceil(D).
        When combined with bilinear pixel sampling, this becomes trilinear filtering.</li>
  </ul>

  <hr>

  <h3>Tradeoffs Between Sampling Techniques</h3>

  <ul>
    <li>
      <strong>Supersampling</strong> reduces aliasing along triangle edges by taking multiple
      samples per pixel and averaging them. It significantly improves geometric edge quality,
      but increases memory usage and runtime proportionally to the sample rate.
    </li>

    <li>
      <strong>Pixel Sampling (Nearest vs Bilinear)</strong> controls how we sample within a
      selected mip level. Nearest is faster but produces blocky texels. Bilinear interpolates
      between neighboring texels, producing smoother results at slightly higher cost.
    </li>

    <li>
      <strong>Level Sampling (Mipmapping)</strong> reduces texture aliasing when the object
      is zoomed out by selecting a lower-resolution prefiltered texture. It requires additional
      memory to store mip levels, but greatly improves visual stability without increasing
      per-pixel sample count.
    </li>
  </ul>

  <p>
  Supersampling improves geometric aliasing. Pixel sampling improves intra-texel smoothness.
  Level sampling improves texture stability at different zoom levels.
  These techniques address different sources of aliasing and can be combined.
  </p>

  <hr>

  <h3>Sampling Comparisons (Using My Own PNG)</h3>

  <h4>L_ZERO + P_NEAREST</h4>
  <img src="screenshot_2-25_21-33-58.png" width="600">
  <p>
  Sampling from level 0 using nearest pixel sampling produces visible blockiness and
  more noticeable high-frequency texture noise when zoomed out.
  </p>

  <h4>L_ZERO + P_LINEAR</h4>
  <img src="screenshot_2-25_21-34-44.png" width="600">
  <p>
  Using bilinear sampling at level 0 smooths local texel transitions,
  but aliasing still occurs when the object becomes small because the texture
  resolution is too high for the pixel footprint.
  </p>

  <h4>L_NEAREST + P_NEAREST</h4>
  <img src="screenshot_2-25_21-35-24.png" width="600">
  <p>
  Selecting the nearest mip level reduces aliasing significantly.
  The texture appears more stable and less noisy when zoomed out.
  </p>

  <h4>L_NEAREST + P_LINEAR</h4>
  <img src="screenshot_2-25_21-35-34.png" width="600">
  <p>
  Combining mip level selection with bilinear pixel sampling produces
  the smoothest and most stable result among the four configurations.
  Texture aliasing is reduced while maintaining smooth transitions.
  </p>

  <hr>

  <h3>Zoomed-Out Stability Comparison</h3>

  <img src="screenshot_2-25_21-37-1.png" width="400">
  <img src="screenshot_2-25_21-37-32.png" width="400">

  <p>
  When zoomed out, L_NEAREST produces a more stable and less shimmering
  appearance compared to L_ZERO. This confirms that mip level computation
  is correctly adapting to screen-space texture footprint.
  </p>

  <p>
  Overall, level sampling with mipmaps improves rendering stability
  without increasing the supersample rate, making it an efficient
  solution for reducing texture aliasing.
  </p>

  

</body>
</html>
