<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>CS184 HW1 - Rasterizer</title>
</head>
<body>
  <h1>Homework 1: Rasterizer</h1>
  <p>Yash Shah — CS184 Spring 2026</p>

  <h2>Task 1: Drawing Single-Color Triangles</h2>

  <h3>Implementation</h3>
  <p>
    To rasterize a triangle, I first compute its axis-aligned bounding box by taking the minimum and maximum
    x and y values across the triangle’s three vertices. I then iterate over all pixels within this box and
    sample at the center of each pixel using (x + 0.5, y + 0.5), as specified in the assignment.
  </p>
  <p>
    For each sample point, I use edge functions to test whether the point lies inside the triangle. If the
    sample is inside the triangle or on its boundary, I fill the pixel with the triangle’s color using
    <code>fill_pixel()</code>.
  </p>

  <h3>Efficiency</h3>
  <p>
    My algorithm only checks pixels inside the triangle’s bounding box rather than scanning the entire framebuffer.
    Each pixel in the bounding box is tested once, so the runtime is proportional to the area of the bounding box.
    This is no worse than a method that checks every sample in the triangle’s bounding box.
  </p>

  <h3>Result (basic/test4.svg + Pixel Inspector)</h3>
  <p>
    The screenshot below was generated using the GUI <code>S</code> hotkey, with the pixel inspector enabled and centered
    on an interesting edge region.
  </p>

  <img src="task1_test4_pixel_inspector.png.png" width="900" />
  
  <h3>Additional Screenshot</h3>
  <img src="task1_test4.png" width="900" />


  <hr>

  <h2>Task 2: Antialiasing by Supersampling</h2>

  <h3>Implementation</h3>

  <p>
  To implement supersampling, I modified the rasterizer to maintain a
  separate supersample buffer (<code>sample_buffer</code>) that stores
  <code>sample_rate</code> color samples per pixel instead of a single
  sample. The buffer size is therefore
  <code>width × height × sample_rate</code>.
  </p>

  <p>
  For triangle rasterization, instead of sampling once at the center
  of each pixel, I subdivide each pixel into a
  <code>sqrt(sample_rate) × sqrt(sample_rate)</code> grid of evenly spaced
  subpixel locations. For each subpixel sample, I perform the same
  edge-function point-in-triangle test used in Task 1.
  If the sample lies inside or on the boundary of the triangle,
  I write the triangle’s color into the corresponding location in
  the supersample buffer.
  </p>

  <p>
  After all primitives are rasterized, I resolve the supersamples
  into the final framebuffer inside
  <code>resolve_to_framebuffer()</code>.
  For each pixel, I average the colors of its
  <code>sample_rate</code> subpixel samples and write the averaged
  result into the RGB framebuffer. This averaging step produces
  partial coverage values near edges, which reduces aliasing artifacts.
  </p>

  <h3>Performance Considerations</h3>

  <p>
  The runtime of the rasterizer increases approximately linearly
  with the sample rate, since each pixel now requires
  <code>sample_rate</code> coverage tests instead of one.
  However, rasterization is still restricted to the triangle’s
  axis-aligned bounding box, so performance remains proportional
  to the bounding box area rather than the entire framebuffer.
  </p>

  <h3>Results (basic/test4.svg)</h3>

  <p><strong>Supersample Rate = 1</strong></p>
  <img src="screenshot_2-24_20-25-13.png" width="900" />

  <p><strong>Supersample Rate = 4</strong></p>
  <img src="screenshot_2-24_20-25-30.png" width="900" />

  <p><strong>Supersample Rate = 16</strong></p>
  <img src="screenshot_2-24_20-26-2.png" width="900" />

  <h3>Analysis</h3>

  <p>
  At a sample rate of 1, triangle edges exhibit visible aliasing
  (stair-step artifacts), especially along shallow or diagonal edges.
  This occurs because each pixel is classified as either fully inside
  or fully outside the triangle.
  </p>

  <p>
  At a sample rate of 4, edge transitions become smoother because
  pixels along boundaries may now have partial coverage. The
  averaged subpixel samples produce intermediate colors that reduce
  the stair-step effect.
  </p>

  <p>
  At a sample rate of 16, edges appear significantly smoother,
  with much finer transitions along triangle boundaries.
  The improvement is especially noticeable along thin or slanted edges,
  where higher sampling density better approximates the true geometric
  coverage of the triangle.
  </p>

  <hr>

  <h3>Extra Credit: Jittered Sampling</h3>

  <p>
  In addition to regular grid supersampling, I implemented jittered
  sampling. Instead of placing subpixel samples at fixed grid locations,
  each sample position is randomly perturbed within its subpixel cell
  using a deterministic hash-based offset. This keeps sampling stable
  between frames while introducing randomness in sample placement.
  </p>

  <p>
  Grid supersampling reduces aliasing but may introduce structured
  patterns along certain edges due to the regular alignment of the grid.
  Jittered sampling breaks this regularity and distributes error more
  randomly, which reduces visible structured artifacts.
  </p>

  <p><strong>Grid Sampling (sample rate = 16)</strong></p>
  <img src="screenshot_2-24_20-31-4.png" width="900" />

  <p><strong>Jittered Sampling (sample rate = 16)</strong></p>
  <img src="screenshot_2-24_20-33-56.png" width="900" />

  <p>
  Compared to regular grid sampling, jittered sampling produces
  less structured stair-step artifacts along diagonal edges.
  While both methods significantly reduce aliasing compared to
  sample rate 1, jittered sampling appears visually smoother
  because the aliasing error is less correlated.
  </p>


  <hr>

  <h2>Task 3: Transforms</h2>

  <h3>Custom Robot (my_robot.svg)</h3>

  <p>
  After implementing the <code>translate</code>, <code>scale</code>, and
  <code>rotate</code> transformation matrices in <code>transforms.cpp</code>,
  the original <code>robot.svg</code> rendered correctly.
  To demonstrate hierarchical transformations, I created a modified
  version of the robot called <code>my_robot.svg</code>.
  </p>

  <p>
  I changed the robot’s color and adjusted several group transforms
  to create a more dynamic pose. The right arm group was rotated
  (using <code>rotate(-40)</code>) to simulate a waving motion.
  The left and right leg groups were rotated in opposite directions
  (<code>rotate(20)</code> and <code>rotate(-20)</code>) to give the appearance
  of running. I also slightly rotated the head to make the pose
  feel more expressive.
  </p>

  <p>
  Because each limb is defined inside a <code>&lt;g&gt;</code> group,
  applying a transformation to the group automatically affects
  all child polygons within that limb. This demonstrates how
  hierarchical transforms propagate through the SVG transformation
  stack via matrix multiplication.
  </p>

  <img src="screenshot_2-24_23-12-33.png" width="900" />

  <hr>
  <h2>Task 4: Barycentric Coordinates</h2>

  <h3>Explanation</h3>
  <p>
  Barycentric coordinates represent any point inside a triangle as a weighted combination
  of the triangle’s three vertices. For a point P inside a triangle with vertices V0, V1,
  and V2, we compute three weights (α, β, γ) such that:
  </p>

  <p>
  P = αV0 + βV1 + γV2, and α + β + γ = 1.
  </p>

  <p>
  Intuitively, each weight measures how close the point is to a vertex. If P is near V0,
  then α is large; if P lies on the edge opposite V0, then α becomes 0. In our rasterizer,
  we compute these weights using edge functions (signed area tests). A point is inside the
  triangle if the weights are all nonnegative (or all nonpositive, depending on winding).
  </p>

  <p>
  Once we have (α, β, γ), we can smoothly interpolate any per-vertex quantity across the
  triangle. For this task, we interpolate color: the final color at P is α·C0 + β·C1 + γ·C2.
  This produces smooth color gradients instead of flat-colored triangles.
  </p>

  <h3>Gradient Example (interpolated colors)</h3>
  <img src="screenshot_2-25_15-54-22.png" width="900" />

  <h3>Color Wheel Result (test7.svg, sample rate 1)</h3>
  <img src="screenshot_2-24_23-58-21.png" width="900" />

  <h2>Task 5: Pixel Sampling for Texture Mapping</h2>

  <h3>Overview</h3>

  <p>
  Pixel sampling determines how we compute the color of a pixel when mapping a texture onto a triangle. 
  After computing barycentric coordinates for each sub-sample inside a pixel, we interpolate the 
  corresponding texture coordinates (u, v). These (u, v) coordinates lie in the continuous range [0, 1], 
  but the texture itself is stored as a discrete grid of texels. Pixel sampling determines how we convert 
  this continuous texture coordinate into a final color value.
  </p>

  <p>
  In this task, I implemented two pixel sampling methods:
  </p>

  <ul>
    <li><strong>Nearest neighbor sampling</strong></li>
    <li><strong>Bilinear interpolation</strong></li>
  </ul>

  <p>
  For Task 5, only level 0 of the mipmap (full resolution texture) was used.
  </p>

  <hr>

  <h3>Implementation Details</h3>

  <p>
  In <code>rasterize_textured_triangle</code>, I reused the supersampling and barycentric interpolation 
  logic from Task 4. For each sub-sample inside a pixel:
  </p>

  <ol>
    <li>Compute barycentric coordinates.</li>
    <li>Interpolate texture coordinates (u, v).</li>
    <li>Use the selected pixel sampling method (psm) to sample the texture at level 0.</li>
    <li>Store the resulting color in the sample buffer.</li>
  </ol>

  <p>
  Nearest sampling converts (u, v) into the closest texel index using rounding. 
  Bilinear sampling computes a weighted average of the four surrounding texels using linear interpolation 
  in both the x and y directions.
  </p>

  <hr>

  <h3>Nearest vs. Bilinear Sampling</h3>

  <h4>Nearest Sampling</h4>

  <p>
  Nearest neighbor sampling selects the single texel whose center is closest to the 
  continuous (u, v) coordinate. This method is fast and simple but can produce visible 
  blockiness and abrupt color transitions.
  </p>

  <img src="nearest_pixel_sampler.png" width="600">
  <p><em>Nearest sampling, 1 sample per pixel</em></p>

  <img src="16_pixel_nearest.png" width="600">
  <p><em>Nearest sampling, 16 samples per pixel</em></p>

  <p>
  With 1 sample per pixel, the texture appears slightly blocky, especially when zoomed in 
  around coastlines and grid lines. Increasing to 16 samples per pixel smooths triangle 
  edges (geometry aliasing), but the texture itself still exhibits blockiness because 
  nearest sampling does not blend between texels.
  </p>

  <hr>

  <h4>Bilinear Sampling</h4>

  <p>
  Bilinear interpolation samples the four surrounding texels and blends them 
  based on the fractional part of the texture coordinate. This produces smoother 
  transitions between texels.
  </p>

  <img src="Bbilinear_1.png" width="600">
  <p><em>Bilinear sampling, 1 sample per pixel</em></p>

  <img src="bilinear_16.png" width="600">
  <p><em>Bilinear sampling, 16 samples per pixel</em></p>

  <p>
  Compared to nearest sampling, bilinear interpolation produces smoother 
  coastlines and grid lines. The texture transitions appear softer, and 
  individual texel boundaries are less visible. With 16 samples per pixel, 
  both texture smoothness and geometric edge smoothness improve further.
  </p>

  <hr>

  <h3>Pixel Inspector Comparison</h3>

  <p>
  Using the pixel inspector and zooming into the grid lines on the globe, 
  the difference between the two methods becomes more apparent.
  </p>

  <img src="pixel_inspector_normal.png" width="400">
  <p><em>Nearest sampling (zoomed view)</em></p>

  <img src="pixel_inspector_bilinear.png" width="400">
  <p><em>Bilinear sampling (zoomed view)</em></p>

  <p>
  Nearest sampling produces visible square texel blocks and abrupt color changes. 
  Bilinear sampling blends neighboring texels, producing smoother gradients 
  and less noticeable pixel boundaries.
  </p>

  <hr>

  <h3>Discussion: When Is the Difference Large?</h3>

  <p>
  The difference between nearest and bilinear sampling becomes more significant when:
  </p>

  <ul>
    <li>The texture contains high-frequency details (thin lines, sharp edges, text).</li>
    <li>The texture is magnified (zoomed in).</li>
    <li>The surface is viewed at an angle.</li>
  </ul>

  <p>
  Nearest sampling preserves sharp texel boundaries, which can result in 
  visible aliasing artifacts. Bilinear sampling reduces these artifacts by 
  interpolating between texels, creating smoother transitions. However, bilinear 
  sampling can slightly blur fine details compared to nearest sampling.
  </p>

  <p>
  In summary, nearest sampling is faster but produces more aliasing, 
  while bilinear sampling improves visual quality by smoothing texture transitions.
  </p>

  <hr>

  <h3>Relationship Between Pixel Sampling and Supersampling</h3>

  <p>
  It is important to distinguish between pixel sampling and supersampling. 
  Pixel sampling determines how a texture color is computed from texture coordinates (u, v). 
  Nearest and bilinear sampling affect how smoothly the texture itself appears.
  </p>

  <p>
  Supersampling, on the other hand, reduces aliasing along triangle edges by 
  taking multiple sub-samples within each pixel and averaging them. Increasing 
  the supersample rate improves geometric edge smoothness but does not change 
  how individual texels are filtered.
  </p>

  <p>
  Therefore:
  </p>

  <ul>
    <li>Nearest vs. bilinear sampling affects texture sharpness and smoothness.</li>
    <li>1 sample vs. 16 samples per pixel affects triangle edge aliasing.</li>
  </ul>

  <p>
  These two techniques address different sources of aliasing in the rendering pipeline.
  </p>

  <h2>Task 6: Level Sampling with Mipmaps for Texture Mapping</h2>

  <h3>What is level sampling?</h3>
  <p>
  Level sampling decides <em>which resolution</em> of the texture (which mipmap level) to sample from.
  When a textured surface becomes small on the screen (zooming out), many texels in the original
  (high-resolution) texture may map into a single screen pixel. If we always sample from level 0,
  high-frequency details in the texture can cause strong aliasing artifacts such as shimmering,
  moir&eacute; patterns, and noisy edges.
  </p>

  <p>
  Mipmaps solve this by storing prefiltered versions of the texture at decreasing resolutions.
  Level sampling chooses the appropriate mip level based on how quickly the texture coordinates
  (u, v) change across the screen.
  </p>

  <hr>

  <h3>Implementation</h3>
  <p>
  To compute the mip level, for each sample point inside the triangle I computed the texture
  coordinates at three screen locations: (x, y), (x+1, y), and (x, y+1). These correspond to
  <code>sp.p_uv</code>, <code>sp.p_dx_uv</code>, and <code>sp.p_dy_uv</code>. In <code>Texture::get_level</code>,
  I computed the difference vectors (<code>p_dx_uv - p_uv</code>) and (<code>p_dy_uv - p_uv</code>), scaled them
  by the width/height of the level-0 texture to convert into texel space, and then used the lecture
  formula:
  </p>

  <ul>
    <li>Compute the magnitude of the UV derivatives in texel space in the x and y directions.</li>
    <li>Use the maximum of the two magnitudes as the footprint size.</li>
    <li>Return <code>D = log2(footprint)</code> as the mip level.</li>
  </ul>

  <p>
  Finally, <code>Texture::sample</code> performs level sampling based on <code>lsm</code>:
  </p>

  <ul>
    <li><strong>L_ZERO</strong>: always samples mip level 0 (full resolution), same as Task 5.</li>
    <li><strong>L_NEAREST</strong>: rounds D to the nearest integer mip level and samples that level.</li>
    <li><strong>L_LINEAR</strong>: linearly interpolates between the two adjacent mip levels
        (floor(D) and ceil(D)). When combined with bilinear pixel sampling, this becomes
        <em>trilinear filtering</em>.</li>
  </ul>

  <hr>

  <h3>Tradeoffs: supersampling vs pixel sampling vs level sampling</h3>

  <p>
  After Task 6, we can independently control three techniques: supersampling, pixel sampling,
  and level sampling. Each has different tradeoffs:
  </p>

  <ul>
    <li>
      <strong>Supersampling (SSAA)</strong> reduces aliasing along triangle edges by taking multiple
      samples per pixel and averaging them. It is powerful for geometric edges but is expensive
      because it increases the number of samples stored and computed (more time and memory).
    </li>

    <li>
      <strong>Pixel sampling (nearest vs bilinear)</strong> controls how we sample within a single mip level.
      Nearest sampling is faster but can look blocky. Bilinear sampling is smoother but slightly more expensive
      and can blur fine details.
    </li>

    <li>
      <strong>Level sampling (mipmapping)</strong> reduces texture aliasing when zoomed out by sampling from a
      lower-resolution prefiltered texture. It requires additional memory for storing the mipmap pyramid,
      but it improves stability and reduces shimmering without needing a very high supersample rate.
    </li>
  </ul>

  <hr>

  <h3>Sampling Comparisons (Using My Own PNG)</h3>
  <p>
  Below are four renders of the same textured scene using my own PNG, showing the combinations requested:
  </p>

  <h4>L_ZERO + P_NEAREST</h4>
  <img src="t6_L0_PN.png" width="600">
  <p><em>Level 0 with nearest pixel sampling. Aliasing is more visible and texels appear blocky.</em></p>

  <h4>L_ZERO + P_LINEAR</h4>
  <img src="t6_L0_PL.png" width="600">
  <p><em>Level 0 with bilinear pixel sampling. Transitions are smoother, but aliasing can still occur when zoomed out.</em></p>

  <h4>L_NEAREST + P_NEAREST</h4>
  <img src="t6_LN_PN.png" width="600">
  <p><em>Nearest mip level with nearest pixel sampling. Texture aliasing is reduced compared to L_ZERO.</em></p>

  <h4>L_NEAREST + P_LINEAR</h4>
  <img src="t6_LN_PL.png" width="600">
  <p><em>Nearest mip level with bilinear sampling. This generally produces the best balance of stability and smoothness among the four.</em></p>

  <p>
  Overall, L_NEAREST significantly reduces texture aliasing when the object is zoomed out, because it samples
  from a mip level whose resolution better matches the pixel footprint on screen. Bilinear pixel sampling further
  smooths within that chosen mip level.
  </p>

  

</body>
</html>
